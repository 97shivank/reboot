# -*- coding: utf-8 -*-
"""Reboot_K_ANN_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NAlmZS8iGOCLKDLcuhlXJBh6F_tB2xsi
"""

import sys
import sklearn
import numpy as np
import zipfile
import pandas as pd
import matplotlib as plt
from sklearn.preprocessing import LabelEncoder,OneHotEncoder
# np.set_printoptions(threshold=sys.maxsize)
from sklearn import preprocessing

train=pd.read_csv('../input/dataset/TrainingData.csv')
test=pd.read_csv('../input/dataset/TestData.csv')
sample=pd.read_csv('../input/dataset/SubmissionFormat.csv')

def mean_iou(y_true, y_pred):
   score, up_opt = tf.metrics.mean_iou(y_true, y_pred, NUM_CLASSES)
   K.get_session().run(tf.local_variables_initializer())
   with tf.control_dependencies([up_opt]):
       score = tf.identity(score)
   return score

training_data = train[['Facility_or_Department', 'Function_Description','Fund_Description',
                       'Job_Title_Description', 'Location_Description','Object_Description',
                       'Position_Extra', 'Program_Description', 'SubFund_Description',
                       'Sub_Object_Description', 'Text_1', 'Text_2','Text_3','Text_4', 'Total','FTE']]

labels = (train[['Function','Object_Type','Operating_Status','Position_Type','Pre_K', 'Reporting',
                'Sharing','Student_Type', 'Use']])

test_data = test[['Facility_or_Department', 'Function_Description','Fund_Description',
                       'Job_Title_Description', 'Location_Description','Object_Description',
                       'Position_Extra', 'Program_Description', 'SubFund_Description',
                       'Sub_Object_Description', 'Text_1', 'Text_2','Text_3','Text_4', 'Total','FTE']]

training_data=training_data.drop(['Total'],axis=1)
training_data=training_data.drop(['FTE'],axis=1)

test_data=test_data.drop(['Total'], axis = 1)
test_data=test_data.drop(['FTE'], axis = 1)

for i in range(training_data.shape[1]):
    labelencoder_X=LabelEncoder();
    training_data.iloc[:,i] = training_data.iloc[:,i].astype(str)
    training_data.iloc[:,i] = training_data.iloc[:,i].str.replace('[^\w\s]','')
    training_data.iloc[:,i] = labelencoder_X.fit_transform(training_data.iloc[:,i])

for i in range(labels.shape[1]):
    labelencoder_X=LabelEncoder();
    labels.iloc[:,i] = labels.iloc[:,i].astype(str)
    labels.iloc[:,i] = labels.iloc[:,i].str.replace('[^\w\s]','')
    labels.iloc[:,i] = labelencoder_X.fit_transform(labels.iloc[:,i])

for i in range(test_data.shape[1]):
    labelencoder_X=LabelEncoder();
    test_data.iloc[:,i] = test_data.iloc[:,i].astype(str)
    test_data.iloc[:,i] = test_data.iloc[:,i].str.replace('[^\w\s]','')
    test_data.iloc[:,i] = labelencoder_X.fit_transform(test_data.iloc[:,i])

import keras
from keras.models import Sequential#to initialise our NN
from keras.layers import Dense#to build layers of our ANN
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

x=training_data.iloc[:,0:14].values
y=labels.iloc[:,0].values
p=np.unique(y)
y=np.reshape(y,(400277,1))
X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)
test_data=sc.fit_transform(test_data)
np.unique(y)
classifier = Sequential()
classifier.add(Dense(units = 14,kernel_initializer = 'uniform', activation = 'relu', input_dim=14))
classifier.add(Dense(units = 9+len(p), kernel_initializer = 'uniform', activation = 'relu'))
classifier.add(Dense(units = 9+len(p), kernel_initializer = 'uniform', activation = 'relu'))
classifier.add(Dense(units = len(p), kernel_initializer = 'uniform', activation = 'softmax'))#if categorical data then see video for activation 
classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])#if categorical data then see video for loss funtion
classifier.fit(X_train, y_train,validation_split=0.2,batch_size = 1024, epochs = 500)
prob= np.array(classifier.predict(test_data))
# pred=classifier.predict(X_test.iloc[0:100,:])
score = classifier.evaluate(X_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
for i in range(1,9):
    x=training_data.iloc[:,0:14].values
    y=labels.iloc[:,i].values
    p=np.unique(y)
    y=np.reshape(y,(400277,1))
    X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)
    sc=StandardScaler()
    X_train=sc.fit_transform(X_train)
    X_test=sc.transform(X_test)
    classifier = Sequential()
    classifier.add(Dense(units = 14,kernel_initializer = 'uniform', activation = 'relu', input_dim=14))
    classifier.add(Dense(units = 9+len(p), kernel_initializer = 'uniform', activation = 'relu'))
    classifier.add(Dense(units = 9+len(p), kernel_initializer = 'uniform', activation = 'relu'))
    classifier.add(Dense(units = len(p), kernel_initializer = 'uniform', activation = 'softmax'))#if categorical data then see video for activation 
    classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])#if categorical data then see video for loss funtion
    classifier.fit(X_train, y_train,validation_split=0.2,batch_size = 1024, epochs = 200)
    y_pred = np.array(classifier.predict(test_data))
    prob=np.concatenate((prob,y_pred), axis=1)
    score = classifier.evaluate(X_test, y_test, verbose=0)
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])

np.savetxt("final_prob.csv",prob,delimiter=",")

classifier.save('Reboot_ANN_final.h5')

